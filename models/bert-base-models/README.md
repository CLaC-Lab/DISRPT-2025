# BERT-based Model Experiments

This directory contains Jupyter notebooks for experiments with BERT-based multilingual models:  
- `bert-base-multilingual-cased`  
- `xlm-roberta-base`  
- `xlm-roberta-large`  

The experiments are organized into two categories:

## 1. Argument Ordering
- Focus: Testing different argument ordering strategies (natural vs. relation-directed).  
- Each notebook includes both the **code** and the **results**.  

## 2. Progressive Unfreezing
- Focus: Training with different unfreezing ratios (e.g., top 25%, 50%, 75% of layers).  
- Each notebook includes both the **code** and the **results**.  

---

If you cannot view the notebooks on GitHub, you can open them on Hugging Face:  
[View notebooks on Hugging Face](https://huggingface.co/datasets/nawarturk/DISRPT-2025-Task3/tree/main/models/bert-base-models)
